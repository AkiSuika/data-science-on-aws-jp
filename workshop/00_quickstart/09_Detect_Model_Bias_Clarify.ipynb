{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Clarifyを用いたモデルバイアスの検知"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Amazon Science: _[How Clarify helps machine learning developers detect unintended bias](https://www.amazon.science/latest-news/how-clarify-helps-machine-learning-developers-detect-unintended-bias)_ \n",
    "\n",
    "[<img src=\"img/amazon_science_clarify.png\"  width=\"100%\" align=\"left\">](https://www.amazon.science/latest-news/how-clarify-helps-machine-learning-developers-detect-unintended-bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用語集\n",
    "\n",
    "* **バイアス**:\n",
    "年齢や収入層などの異なるグループ間で、学習データやモデルの予測動作に生じる不均衡のこと。バイアスは、モデルの学習に使用したデータやアルゴリズムから生じることがあります。例えば、MLモデルが主に中高年のデータで学習された場合、若年層や高齢者に対する予測を行う際に精度が低くなる可能性があります。\n",
    "\n",
    "* **バイアスメトリクス**: \n",
    "潜在的なバイアスの度合いを示す数値を返す関数。\n",
    "\n",
    "* **バイアスレポート**:\n",
    "分析対象のデータセット、またはデータセットとモデルの組み合わせに対するバイアスメトリクスのコレクション。\n",
    "\n",
    "* **ラベル**:\n",
    "機械学習モデルのトレーニングのターゲットとなる特徴量。\n",
    "\n",
    "* **ポジティブラベル値**:\n",
    "サンプル内の特定の人口集団（年代、性別など）でよく観測されるラベル値。言い換えれば、サンプルがポジティブな結果を持つことを示しています。\n",
    "\n",
    "* **ネガティブラベル値**:\n",
    "サンプル内の特定の人口集団（年代、性別など）であまり観測されないラベル値。言い換えれば、サンプルがネガティブな結果を持つことを示しています。\n",
    "\n",
    "* **ファセット**:\n",
    "バイアスの分析対象となる属性を含むカラムまたは特徴量のこと。（訳注: 例えばデータセットに男女間の差異がないかを分析したい場合は、「性別」のカラムがファセット（側面）となります。）\n",
    "\n",
    "* **ファセット値**:\n",
    "バイアスが含まれ得る属性の特徴値。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トレーニング後バイアスメトリクス\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html\n",
    "\n",
    "* **予測正例ラベル比率の差、Difference in Positive Proportions in Predicted Labels (DPPL)**:\n",
    "有利なファセットaと不利なファセットdの間の正例の予測の比率の差を測定。\n",
    "\n",
    "* **異種の影響度、Disparate Impact (DI)**:\n",
    "有利なファセットaと不利なファセットdの予測されたラベル比率同士の割合を測定。\n",
    "\n",
    "* **条件付き受け入れの差、Difference in Conditional Acceptance (DCAcc)**:\n",
    "実際のポジティブラベルの数とモデルによって予測されたポジティブラベルの数の比率をファセット間で比較し、同じであるかどうかを評価。\n",
    "\n",
    "* **条件付き拒否の差、Difference in Conditional Rejection (DCR)**:\n",
    "実際のネガティブラベルの数とモデルによって予測されたネガティブラベルの数の比率をファセット間で比較し、同じであるかどうかを評価。\n",
    "\n",
    "* **再現率の差、Recall Difference (RD)**:\n",
    "有利なファセットと不利なファセットに対するモデルの再現率（recall）を比較。\n",
    "\n",
    "* **受け入れ率の差、Difference in Acceptance Rates (DAR)**:\n",
    "有利なファセットと不利なファセットとで、予測陽性（TP + FP）に対する真陽性（TP）の比率の差を測定。\n",
    "\n",
    "* **拒否率の差、Difference in Rejection Rates (DRR)**:\n",
    "有利なファセットと不利なファセットとで、真陰性（TN）と予測陰性（TN + FN）の比率の差を測定。\n",
    "\n",
    "* **正確度の差、Accuracy Difference (AD)**:\n",
    "有利なファセットと不利なファセットとで、正確度の差を測定。\n",
    "\n",
    "* **処理の平等性、Treatment Equality (TE)**:\n",
    "有利なファセットと不利なファセットの間の偽陽性と偽陰性の比率の差を測定。\n",
    "\n",
    "* **予測ラベルにおける条件付き人口統計学的格差、Conditional Demographic Disparity in Predicted Labels (CDDPL)**:\n",
    "ファセット全体だけでなく、サブグループごとの予測ラベルの格差を測定。\n",
    "\n",
    "* **反実例のフリップテスト、Counterfactual Fliptest (FT)**:\n",
    "ファセットdの各サンプルと類似したファセットaのサンプルを調べ、異なるモデル予測を持っているかどうかを評価します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "import botocore.config\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    user_agent_extra='dsoaws/1.0'\n",
    ")\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", \n",
    "                            region_name=region,\n",
    "                            config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バイアス分析用のテストデータ\n",
    "\n",
    "テストデータは、モデル入力と合うようにJSONLinesフォーマットで作成しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_bias_path = \"./data-clarify/test_data_bias.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 $test_data_bias_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_bias_s3_uri = sess.upload_data(bucket=bucket, key_prefix=\"bias/test_data_bias\", path=test_data_bias_path)\n",
    "test_data_bias_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $test_data_bias_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store test_data_bias_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トレーニング後モデルバイアス分析を実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)[\"PipelineExecutionSummaries\"]\n",
    "pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "print(pipeline_execution_status)\n",
    "\n",
    "while pipeline_execution_status == \"Executing\":\n",
    "    try:\n",
    "        executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)[\"PipelineExecutionSummaries\"]\n",
    "        pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "    except Exception as e:\n",
    "        print(\"Please wait...\")\n",
    "        time.sleep(30)\n",
    "\n",
    "pprint(executions_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプライン実行ステップを表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "print(pipeline_execution_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_execution_arn = executions_response[0][\"PipelineExecutionArn\"]\n",
    "print(pipeline_execution_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "steps = sm.list_pipeline_execution_steps(PipelineExecutionArn=pipeline_execution_arn)\n",
    "\n",
    "pprint(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作成したモデルを確認\n",
    "_注意:  トレーニングしたモデルが Evaluation ステップをパス（> 正確度の閾値）していない場合、作成されません。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for execution_step in steps[\"PipelineExecutionSteps\"]:\n",
    "    if execution_step[\"StepName\"] == \"CreateModel\":\n",
    "        model_arn = execution_step[\"Metadata\"][\"Model\"][\"Arn\"]\n",
    "        break\n",
    "print(model_arn)\n",
    "\n",
    "pipeline_model_name = model_arn.split(\"/\")[-1]\n",
    "print(pipeline_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMakerClarifyProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import clarify\n",
    "\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.c5.2xlarge\", \n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataConfig と ModelConfig を書く\n",
    "\n",
    "`DataConfig` オブジェクトはデータの入出力に関するいくつかの基本的な情報をClarifyに伝えるものです。\n",
    "入力データセットをどこに置くか、出力をどこに保存するか、対象となるカラム（`label`）、ヘッダー名、データセットの種類などを指定します。\n",
    "\n",
    "同様に、`ModelConfig` オブジェクトはトレーニングしたモデルに関する情報を設定し、`ModelPredictedLabelConfig` は予測値のフォーマットに関する情報をClarifyに伝えます。 \n",
    "\n",
    "**注意**: SageMaker Clarifyでは、本番稼働中のモデルへの追加トラフィックを避けるために、処理実行時に専用のエンドポイントを立ち上げたり、停止させたりします。\n",
    "`ModelConfig` は、Clarifyの処理中にモデルを実行するために使用する、希望のインスタンスタイプとインスタンス数を指定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_report_prefix = \"bias/report-{}\".format(pipeline_model_name)\n",
    "\n",
    "bias_report_output_path = \"s3://{}/{}\".format(bucket, bias_report_prefix)\n",
    "\n",
    "data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=test_data_bias_s3_uri,\n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=\"star_rating\",\n",
    "    features=\"features\",\n",
    "    # label must be last, features in exact order as passed into model\n",
    "    headers=[\"review_body\", \"product_category\", \"star_rating\"],\n",
    "    dataset_type=\"application/jsonlines\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(\n",
    "    model_name=pipeline_model_name,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    instance_count=1,\n",
    "    content_type=\"application/jsonlines\",\n",
    "    accept_type=\"application/jsonlines\",\n",
    "    # {\"features\": [\"the worst\", \"Digital_Software\"]}\n",
    "    content_template='{\"features\":$features}',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _注意: `label` にはモデル予測結果のJSONのキーをセットしています。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_config = clarify.ModelPredictedLabelConfig(label=\"predicted_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiasConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[\n",
    "        5,\n",
    "        4,\n",
    "    ],  # カテゴリカルなデータ型の場合は「ポジティブ」なラベルを指定し、連続値の場合は閾値を指定する。\n",
    "    facet_name=\"product_category\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clarifyジョブを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor.run_post_training_bias(\n",
    "    data_config=data_config,\n",
    "    data_bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    #    methods='all', # FlipTest requires all columns to be numeric\n",
    "    methods=[\"DPPL\", \"DI\", \"DCA\", \"DCR\", \"RD\", \"DAR\", \"DRR\", \"AD\", \"TE\"],\n",
    "    wait=False,\n",
    "    logs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_post_training_bias_processing_job_name = clarify_processor.latest_job.job_name\n",
    "run_post_training_bias_processing_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\">Processing Job</a></b>'.format(\n",
    "            region, run_post_training_bias_processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(\n",
    "            region, run_post_training_bias_processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}?prefix={}/\">S3 Output Data</a> After The Processing Job Has Completed</b>'.format(\n",
    "            bucket, bias_report_prefix\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "running_processor = sagemaker.processing.ProcessingJob.from_processing_name(\n",
    "    processing_job_name=run_post_training_bias_processing_job_name, sagemaker_session=sess\n",
    ")\n",
    "\n",
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "pprint(processing_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_processor.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3からレポートをダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $bias_report_output_path/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $bias_report_output_path ./generated_bias_report/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"./generated_bias_report/report.html\">Bias Report</a></b>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studio内でバイアスレポートを閲覧\n",
    "StudioではExperiments and trialsから結果を閲覧できます。\n",
    "\n",
    "<img src=\"img/bias_report.gif\">\n",
    "\n",
    "それぞれのバイアスメトリクスに対する詳細な説明とともにサンプルが記載されています。\n",
    "\n",
    "<img src=\"img/bias_detail.gif\">\n",
    "\n",
    "また、便利なテーブルとして結果のサマリーを取得できます。\n",
    "\n",
    "<img src=\"img/bias_report_chart.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リソースを解放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
