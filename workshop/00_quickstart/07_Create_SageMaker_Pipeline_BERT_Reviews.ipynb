{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Pipelines\n",
    "\n",
    "Amazon SageMaker Pipelinesでは以下をサポートしています。\n",
    "\n",
    "* **Pipeline** - SageMakerジョブのオーケストレーションとリソース作成に用いるステップや条件の有向非巡回グラフ。\n",
    "* **Processing Job Step** - 特徴量エンジニアリング、データ検証、モデル評価、モデル解釈などのデータ処理ワークロードを実行するための、SageMakerのシンプルなマネージドエクスペリエンス。\n",
    "* **Training Job Step** - トレーニングデータセットからのサンプルを提示することで、予測を行うためのモデルを訓練する反復的なプロセス。\n",
    "* **Conditional Step** - パイプライン内の条件付き実行分岐を提供する。\n",
    "* **Registering Model** - Amazon SageMakerでデプロイできるモデルを作成するために使用されるモデルレジストリ内にモデルパッケージリソースを作成する。\n",
    "* **Parameterized Execution** - パラメータを与えることでパイプラインの実行を調整可能にする。\n",
    "* **Transform Job Step** - データセットのバッチ変換。データセットのトレーニングや推論を妨げるノイズやバイアスを除去するためにデータを前処理したり、大規模なデータセットの推論結果を得たり、永続的なエンドポイントを必要としないときに推論を実行するために利用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Studio拡張機能\n",
    "\n",
    "SageMaker Studioは、実験、トレーニングジョブ、パイプラインなどのSageMakerリソースを視覚的に検査するための豊富な機能を備えています。\n",
    "\n",
    "![](img/sm_studio_extensions_pipelines.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTのパイプライン\n",
    "\n",
    "処理（Processing）ステップでは、事前学習済み BERT モデルを使用して `review_body` テキストから BERT 埋め込みを作成するための特徴量エンジニアリングを実行し、データセットをトレーニング、検証、およびテストファイルに分割します。\n",
    "Tensorflow のトレーニングに最適化するために、ファイルを TFRecord 形式で保存します。\n",
    "\n",
    "トレーニング（Training）ステップでは、BERTモデルをCustomer Reviews Datasetに合わせてファインチューニングし、入力の `review_body` に対する `star_rating` を予測するために新しい分類レイヤーを追加します。\n",
    "\n",
    "評価（Evaluation）ステップでは、トレーニングされたモデルとテストデータセットを入力とし、分類評価メトリクスを含むJSONファイルを生成します。\n",
    "\n",
    "条件（Condition）ステップでは、評価ステップで求めたモデルの精度がある閾値を超えた場合に、このモデルを登録します。\n",
    "\n",
    "![](img/bert_sagemaker_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで作成するパイプラインは、前処理、トレーニング、評価、モデル登録という典型的な機械学習アプリケーションのパターンに従っています。\n",
    "\n",
    "![A typical ML Application pipeline](img/pipeline-full.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "import botocore.config\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    user_agent_extra='dsoaws/1.0'\n",
    ")\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", \n",
    "                            region_name=region,\n",
    "                            config=config)\n",
    "s3 = boto3.Session().client(service_name=\"s3\", \n",
    "                            region_name=region,\n",
    "                            config=config)\n",
    "featurestore_runtime = boto3.Session().client(service_name=\"sagemaker-featurestore-runtime\", \n",
    "                                              region_name=region,\n",
    "                                              config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3パスをセット（パブリックS3バケット）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_public_path_tsv = \"s3://amazon-reviews-pds/tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store s3_public_path_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3出力先パスをセット（アカウント内のプライベートS3バケット）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_private_path_tsv = \"s3://{}/amazon-reviews-pds/tsv\".format(bucket)\n",
    "print(s3_private_path_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store s3_private_path_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パブリックS3バケットからアカウント内のプライベートS3バケットにデータをコピー\n",
    "データセット全体はとても大きいので、ここでは待ち時間を減らすため3つのファイルのみをコピーしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $s3_public_path_tsv/ $s3_private_path_tsv/ --exclude \"*\" --include \"amazon_reviews_us_Digital_Software_v1_00.tsv.gz\"\n",
    "!aws s3 cp --recursive $s3_public_path_tsv/ $s3_private_path_tsv/ --exclude \"*\" --include \"amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\"\n",
    "!aws s3 cp --recursive $s3_public_path_tsv/ $s3_private_path_tsv/ --exclude \"*\" --include \"amazon_reviews_us_Gift_Card_v1_00.tsv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプラインを `Experiment` として追跡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pipeline_name\n",
    "\n",
    "try:\n",
    "    print(\"Using existing pipeline: {}\".format(pipeline_name))\n",
    "except NameError:\n",
    "    timestamp = int(time.time())\n",
    "    pipeline_name = \"BERT-pipeline-{}\".format(timestamp)\n",
    "    print(\"Created Pipeline Name: \" + pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_executions = 0\n",
    "completed_executions = 0\n",
    "\n",
    "try:\n",
    "    existing_pipeline_executions_response = sm.list_pipeline_executions(\n",
    "        PipelineName=pipeline_name,\n",
    "        SortOrder=\"Descending\",\n",
    "    )\n",
    "\n",
    "    if \"PipelineExecutionSummaries\" in existing_pipeline_executions_response.keys():\n",
    "        if len(existing_pipeline_executions_response[\"PipelineExecutionSummaries\"]) > 0:\n",
    "            execution = existing_pipeline_executions_response[\"PipelineExecutionSummaries\"][0]\n",
    "            if \"PipelineExecutionStatus\" in execution:\n",
    "                if execution[\"PipelineExecutionStatus\"] == \"Executing\":\n",
    "                    running_executions = running_executions + 1\n",
    "                else:\n",
    "                    completed_executions = completed_executions + 1\n",
    "\n",
    "            print(\n",
    "                \"[INFO] You have {} Pipeline execution(s) currently running and {} execution(s) completed.\".format(\n",
    "                    running_executions, completed_executions\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        print(\"[OK] Please continue.\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if running_executions == 0:\n",
    "    timestamp = int(time.time())\n",
    "    pipeline_name = \"BERT-pipeline-{}\".format(timestamp)\n",
    "    print(\"Created Pipeline Name: \" + pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pipeline_experiment_name\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "\n",
    "try:\n",
    "    pipeline_experiment_name\n",
    "except NameError:\n",
    "    pipeline_experiment = Experiment.create(\n",
    "        experiment_name=pipeline_name,\n",
    "        description=\"Amazon Customer Reviews BERT Pipeline Experiment\",\n",
    "        sagemaker_boto_client=sm,\n",
    "    )\n",
    "    pipeline_experiment_name = pipeline_experiment.experiment_name\n",
    "    print(\"Created Pipeline Experiment Name: {}\".format(pipeline_experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store pipeline_experiment_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Trial` の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.trial import Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pipeline_trial_name\n",
    "\n",
    "try:\n",
    "    pipeline_trial_name\n",
    "except NameError:\n",
    "    timestamp = int(time.time())\n",
    "    pipeline_trial = Trial.create(\n",
    "        trial_name=\"trial-{}\".format(timestamp), experiment_name=pipeline_experiment_name, sagemaker_boto_client=sm\n",
    "    )\n",
    "    pipeline_trial_name = pipeline_trial.trial_name\n",
    "    print(\"Created Trial Name: {}\".format(pipeline_trial_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store pipeline_trial_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプライン実行の調整に用いるパラメータを定義\n",
    "\n",
    "ワークフローパラメータを定義することで、パイプラインをパラメータ化し、パイプラインの定義を変更することなく、パイプラインの実行時に使用される設定を変化させることができます。\n",
    "\n",
    "サポートされているパラメータタイプは以下の通りです。\n",
    "\n",
    "* `ParameterString` - Pythonの `str` 型を表す。\n",
    "* `ParameterInteger` - Pythonの `int` 型を表す。\n",
    "* `ParameterFloat` - Pythonの `float` 型を表す。\n",
    "\n",
    "これらのパラメータは、パイプラインの実行時にオーバーライド可能なデフォルト値の提供をサポートしています。\n",
    "指定するデフォルト値は、そのパラメータの型のインスタンスでなければなりません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterString,\n",
    "    ParameterInteger,\n",
    "    ParameterFloat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量エンジニアリングステップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Processing Step for Feature Engineering](img/pipeline-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/prepare_dataset_bert.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input_data_s3_uri = \"s3://{}/amazon-reviews-pds/tsv/\".format(bucket)\n",
    "print(raw_input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプラインパラメータを定義\n",
    "\n",
    "これらのパラメータは、パイプライン全体で使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT の最大シーケンス長\n",
    "最大シーケンス長 `MaxSeqLength` は、レビューテキストの単語数分布に基づいて選択しました。\n",
    "\n",
    "![](img/max_seq_length_viz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=raw_input_data_s3_uri,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1,\n",
    ")\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.c5.2xlarge\",\n",
    ")\n",
    "\n",
    "max_seq_length = ParameterInteger(\n",
    "    name=\"MaxSeqLength\",\n",
    "    default_value=64,\n",
    ")\n",
    "\n",
    "balance_dataset = ParameterString(\n",
    "    name=\"BalanceDataset\",\n",
    "    default_value=\"True\",\n",
    ")\n",
    "\n",
    "train_split_percentage = ParameterFloat(\n",
    "    name=\"TrainSplitPercentage\",\n",
    "    default_value=0.90,\n",
    ")\n",
    "\n",
    "validation_split_percentage = ParameterFloat(\n",
    "    name=\"ValidationSplitPercentage\",\n",
    "    default_value=0.05,\n",
    ")\n",
    "\n",
    "test_split_percentage = ParameterFloat(\n",
    "    name=\"TestSplitPercentage\",\n",
    "    default_value=0.05,\n",
    ")\n",
    "\n",
    "feature_store_offline_prefix = ParameterString(\n",
    "    name=\"FeatureStoreOfflinePrefix\",\n",
    "    default_value=\"reviews-feature-store-\" + str(timestamp),\n",
    ")\n",
    "\n",
    "feature_group_name = ParameterString(\n",
    "    name=\"FeatureGroupName\",\n",
    "    default_value=\"reviews-feature-group-\" + str(timestamp),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SKLearnProcessor` のインスタンスを作成し、それを `ProcessingStep` で使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={\"AWS_DEFAULT_REGION\": region},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パイプラインステップのキャッシュをセットアップ\n",
    "\n",
    "[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601#Durations) フォーマットを使用して、一定期間のパイプラインステップをキャッシュします。 \n",
    "\n",
    "SageMakerパイプラインステップのキャッシュの詳細はこちらを参照してください: https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"PT1H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、Scikit Learnプロセッサーのインスタンスを使って `ProcessingStep` を構築します。\n",
    "これは、入出力のチャンネルと、処理ステップが実行されたときに走るコード `preprocess-scikit-text-to-bert-feature-store.py` を含みます。\n",
    "既存のPython SDKに慣れている人にとっては、プロセッサーインスタンスの `run` メソッドと非常によく似ていることがわかるかと思います。\n",
    "\n",
    "ステップ自体の入力データとして `ProcessingStep` に渡される `processing_input` パラメータに注目してください。\n",
    "この入力データは、プロセッサーのインスタンスが実行される際に使用されます。\n",
    "\n",
    "また、処理ジョブの出力設定で指定されている `\"bert-train\"`、`\"bert-validation\"`、`\"bert-test\"` という名前のチャンネルにも注意してください。\n",
    "このようなステップの `Properties` は、後続のステップで使用することができ、実行時にはランタイムの値に解決されます。\n",
    "特に、トレーニングステップを定義する際には、このような使い方をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processing_inputs = [\n",
    "    ProcessingInput(\n",
    "        input_name=\"raw-input-data\",\n",
    "        source=input_data,\n",
    "        destination=\"/opt/ml/processing/input/data/\",\n",
    "        s3_data_distribution_type=\"ShardedByS3Key\",\n",
    "    )\n",
    "]\n",
    "\n",
    "processing_outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name=\"bert-train\",\n",
    "        s3_upload_mode=\"EndOfJob\",\n",
    "        source=\"/opt/ml/processing/output/bert/train\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"bert-validation\",\n",
    "        s3_upload_mode=\"EndOfJob\",\n",
    "        source=\"/opt/ml/processing/output/bert/validation\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"bert-test\",\n",
    "        s3_upload_mode=\"EndOfJob\",\n",
    "        source=\"/opt/ml/processing/output/bert/test\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name=\"Processing\",\n",
    "    code=\"preprocess-scikit-text-to-bert-feature-store.py\",\n",
    "    processor=processor,\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    job_arguments=[\n",
    "        \"--train-split-percentage\",\n",
    "        str(train_split_percentage.default_value),\n",
    "        \"--validation-split-percentage\",\n",
    "        str(validation_split_percentage.default_value),\n",
    "        \"--test-split-percentage\",\n",
    "        str(test_split_percentage.default_value),\n",
    "        \"--max-seq-length\",\n",
    "        str(max_seq_length.default_value),\n",
    "        \"--balance-dataset\",\n",
    "        str(balance_dataset.default_value),\n",
    "        \"--feature-store-offline-prefix\",\n",
    "        str(feature_store_offline_prefix.default_value),\n",
    "        \"--feature-group-name\",\n",
    "        str(feature_group_name.default_value),\n",
    "    ],\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "print(processing_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トレーニングステップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Training Step to Train a Model](img/pipeline-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type = ParameterString(name=\"TrainInstanceType\", default_value=\"ml.c5.9xlarge\")\n",
    "\n",
    "train_instance_count = ParameterInteger(name=\"TrainInstanceCount\", default_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トレーニングのハイパーパラメータのセットアップ\n",
    "\n",
    "なお、`max_seq_length` は、上記の処理ステップ用のハイパーパラメータから再利用されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = ParameterInteger(name=\"Epochs\", default_value=1)\n",
    "\n",
    "learning_rate = ParameterFloat(name=\"LearningRate\", default_value=0.00001)\n",
    "\n",
    "epsilon = ParameterFloat(name=\"Epsilon\", default_value=0.00000001)\n",
    "\n",
    "train_batch_size = ParameterInteger(name=\"TrainBatchSize\", default_value=128)\n",
    "\n",
    "validation_batch_size = ParameterInteger(name=\"ValidationBatchSize\", default_value=128)\n",
    "\n",
    "test_batch_size = ParameterInteger(name=\"TestBatchSize\", default_value=128)\n",
    "\n",
    "train_steps_per_epoch = ParameterInteger(name=\"TrainStepsPerEpoch\", default_value=50)\n",
    "\n",
    "validation_steps = ParameterInteger(name=\"ValidationSteps\", default_value=50)\n",
    "\n",
    "test_steps = ParameterInteger(name=\"TestSteps\", default_value=50)\n",
    "\n",
    "train_volume_size = ParameterInteger(name=\"TrainVolumeSize\", default_value=256)\n",
    "\n",
    "use_xla = ParameterString(\n",
    "    name=\"UseXLA\",\n",
    "    default_value=\"True\",\n",
    ")\n",
    "\n",
    "use_amp = ParameterString(\n",
    "    name=\"UseAMP\",\n",
    "    default_value=\"True\",\n",
    ")\n",
    "\n",
    "freeze_bert_layer = ParameterString(\n",
    "    name=\"FreezeBERTLayer\",\n",
    "    default_value=\"False\",\n",
    ")\n",
    "\n",
    "enable_sagemaker_debugger = ParameterString(\n",
    "    name=\"EnableSageMakerDebugger\",\n",
    "    default_value=\"False\",\n",
    ")\n",
    "\n",
    "enable_checkpointing = ParameterString(\n",
    "    name=\"EnableCheckpointing\",\n",
    "    default_value=\"False\",\n",
    ")\n",
    "\n",
    "enable_tensorboard = ParameterString(\n",
    "    name=\"EnableTensorboard\",\n",
    "    default_value=\"False\",\n",
    ")\n",
    "\n",
    "input_mode = ParameterString(\n",
    "    name=\"InputMode\",\n",
    "    default_value=\"File\",\n",
    ")\n",
    "\n",
    "run_validation = ParameterString(\n",
    "    name=\"RunValidation\",\n",
    "    default_value=\"True\",\n",
    ")\n",
    "\n",
    "run_test = ParameterString(\n",
    "    name=\"RunTest\",\n",
    "    default_value=\"False\",\n",
    ")\n",
    "\n",
    "run_sample_predictions = ParameterString(\n",
    "    name=\"RunSamplePredictions\",\n",
    "    default_value=\"False\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルパフォーマンスを追跡するためのメトリクスのセットアップ\n",
    "\n",
    "次のサンプルのログの行は...\n",
    "```\n",
    "[step: 100] val_loss: 0.55 - val_accuracy: 74.64%\n",
    "```\n",
    "\n",
    "...次のメトリクスをCloudWatchに生成します。\n",
    "\n",
    "`validation:loss` =  0.55\n",
    "\n",
    "`validation:accuracy` = 74.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/cloudwatch_validation_metrics.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation:loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation:accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### デバッガーとプロファイラーのセットアップ\n",
    "\n",
    "こちらのドキュメントの通りにDebuggerのルールを定義します:  https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "from sagemaker.debugger import DebuggerHookConfig\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    s3_output_path=\"s3://{}\".format(bucket),\n",
    ")\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500,\n",
    "    framework_profile_params=FrameworkProfile(local_path=\"/opt/ml/output/profiler/\", start_step=5, num_steps=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [ProfilerRule.sagemaker(rule_configs.ProfilerReport())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimatorの作成\n",
    "\n",
    "Estimatorと入力データセットの設定を行います。\n",
    "典型的なトレーニングスクリプトでは、入力チャンネルからデータを読み込み、ハイパーパラメータを使ってトレーニングを設定し、モデルをトレーニングして、後でホストできるようにモデルを`model_dir`に保存します。\n",
    "\n",
    "また、トレーニングしたモデルを保存するモデルパスも指定します。\n",
    "\n",
    "なお、渡された `train_instance_type` パラメータは、パイプラインの他の場所でも使用されたり、渡されたりする可能性があります。\n",
    "この例では、`train_instance_type` はestimatorに渡されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=\"tf_bert_reviews.py\",\n",
    "    source_dir=\"src\",\n",
    "    role=role,\n",
    "    instance_count=train_instance_count,  # 少なくともこの数の入力ファイルがあることを確認してください。利用可能なデータがないとShardedByS3Key分散戦略のジョブは失敗します。\n",
    "    instance_type=train_instance_type,\n",
    "    volume_size=train_volume_size,\n",
    "    py_version=\"py37\",\n",
    "    framework_version=\"2.3.1\",\n",
    "    hyperparameters={\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epsilon\": epsilon,\n",
    "        \"train_batch_size\": train_batch_size,\n",
    "        \"validation_batch_size\": validation_batch_size,\n",
    "        \"test_batch_size\": test_batch_size,\n",
    "        \"train_steps_per_epoch\": train_steps_per_epoch,\n",
    "        \"validation_steps\": validation_steps,\n",
    "        \"test_steps\": test_steps,\n",
    "        \"use_xla\": use_xla,\n",
    "        \"use_amp\": use_amp,\n",
    "        \"max_seq_length\": max_seq_length,\n",
    "        \"freeze_bert_layer\": freeze_bert_layer,\n",
    "        \"enable_sagemaker_debugger\": enable_sagemaker_debugger,\n",
    "        \"enable_checkpointing\": enable_checkpointing,\n",
    "        \"enable_tensorboard\": enable_tensorboard,\n",
    "        \"run_validation\": run_validation,\n",
    "        \"run_test\": run_test,\n",
    "        \"run_sample_predictions\": run_sample_predictions,\n",
    "    },\n",
    "    input_mode=input_mode,\n",
    "    metric_definitions=metrics_definitions,\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    profiler_config=profiler_config,\n",
    "    rules=rules,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニンングステップの設定\n",
    "\n",
    "最後に、estimatorインスタンスを使って、`TrainingStep` を構築します。\n",
    "`TrainingStep`の入力としては、先行する `ProcessingStep` の `Properties` を用います。\n",
    "既存のPython SDKに精通している人にとっては、estimatorの`fit`メソッドに非常に似ていることがわかるかと思います。\n",
    "\n",
    "特に、`TrainingStep` には、`\"train\"`、`\"validation\"`、`\"test\"`の出力チャンネルの `S3Uri` を渡しています。\n",
    "ワークフローステップの `properties` 属性は、describeコールの対応するレスポンスのオブジェクトモデルにマッチします。\n",
    "これらのプロパティは、プレースホルダー値として参照することができ、実行時に解決されるか、または記入されます。\n",
    "例えば、`ProcessingStep` の `properties` 属性は、[DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) レスポンスオブジェクトのオブジェクトモデルにマッチします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name=\"Train\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\"bert-train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\"bert-validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\"bert-test\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "\n",
    "print(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価ステップ\n",
    "\n",
    "![Define a Model Evaluation Step to Evaluate the Trained Model](img/pipeline-4.png)\n",
    "\n",
    "まず、モデルの評価を行うProcessingのステップで指定される評価スクリプトを開発します．\n",
    "\n",
    "評価スクリプト `evaluation.py` は、トレーニング済みモデルとテストデータセットを入力とし、accuracyなどの分類評価メトリクスを含むJSONファイルを生成します。\n",
    "\n",
    "パイプラインの実行後には、生成された `evaluation.json` を調べて分析を行います。\n",
    "\n",
    "評価スクリプトでは、以下を行います。\n",
    "\n",
    "* モデルの読み込み\n",
    "* テストデータの読み込み\n",
    "* テストデータに対する複数の予測を実行\n",
    "* accuracyなどを含んだ分類レポートを作成する\n",
    "* 評価レポートを評価ディレクトリに保存\n",
    "\n",
    "次に、`ScriptProcessor`プロセッサーのインスタンスを作成し、それを`ProcessingStep`で使用します。\n",
    "\n",
    "`processing_instance_type` パラメータがプロセッサーに渡されていることに注意してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "evaluation_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={\"AWS_DEFAULT_REGION\": region},\n",
    "    max_runtime_in_seconds=7200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロセッサーのインスタンスを使用して、`ProcessingStep` を構築します。\n",
    "同時に、入出力チャンネルと、パイプライン実行の際に実行されるコードを渡します。\n",
    "既存のPython SDKに慣れている人にとっては、プロセッサーインスタンスの `run` メソッドと非常によく似ていることがわかるかと思います。\n",
    "\n",
    "`TrainingStep` と `ProcessingStep` の `properties` 属性は、それぞれ [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) と [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) レスポンスオブジェクトのオブジェクトモデルにマッチします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(name=\"EvaluationReport\", output_name=\"metrics\", path=\"evaluation.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_step = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    processor=evaluation_processor,\n",
    "    code=\"evaluate_model_metrics.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/input/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=processing_step.properties.ProcessingInputs[\"raw-input-data\"].S3Input.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input/data\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"metrics\", s3_upload_mode=\"EndOfJob\", source=\"/opt/ml/processing/output/metrics/\"\n",
    "        ),\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        \"--max-seq-length\",\n",
    "        str(max_seq_length.default_value),\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            evaluation_step.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル登録ステップ\n",
    "\n",
    "![](img/pipeline-5.png)\n",
    "\n",
    "トレーニングステップで使用したestimatorインスタンスを使って、`RegisterModel`のインスタンスを構築します。\n",
    "パイプラインで `RegisterModel` を実行した結果はモデルパッケージ（Model Package）になります。\n",
    "モデルパッケージは、推論に必要なすべての要素をパッケージ化した、再利用可能なモデルアーティファクトの抽象化です。\n",
    "主に、使用する推論イメージを定義する推論仕様と、オプションとしてモデルの重みのパスで構成されています。\n",
    "\n",
    "モデルパッケージグループは、モデルパッケージの集合体です。\n",
    "特定のMLビジネス問題のためにモデルパッケージグループを作成し、そこにバージョンやモデルパッケージを追加していくことができます。\n",
    "通常、お客様はSageMakerワークフローパイプラインのためにModelPackageGroupを作成し、ワークフローパイプラインを実行するたびにバージョン/モデルパッケージをグループに追加し続けることを想定しています。\n",
    "\n",
    "`RegisterModel`の構造は、既存のPython SDKに慣れている人にとっては、Estimatorインスタンスの`register`メソッドと非常によく似ていることがわかると思います。\n",
    "\n",
    "特に、`TrainingStep` のプロパティから `S3ModelArtifacts` を渡しています。\n",
    "`TrainingStep`の`properties`属性は、[DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html)レスポンスオブジェクトのオブジェクトモデルと一致しています。\n",
    "\n",
    "後にモデルレジストリやCI/CD作業で使用する特定のモデルパッケージグループ名を提供したことに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_approval_status = ParameterString(name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")\n",
    "\n",
    "deploy_instance_type = ParameterString(name=\"DeployInstanceType\", default_value=\"ml.m5.4xlarge\")\n",
    "\n",
    "deploy_instance_count = ParameterInteger(name=\"DeployInstanceCount\", default_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_name = f\"BERT-Reviews-{timestamp}\"\n",
    "\n",
    "print(model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.3.1\",\n",
    "    instance_type=deploy_instance_type,\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "register_step = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    estimator=estimator,\n",
    "    image_uri=inference_image_uri,  # デフォルトではトレーニングイメージを使用するため、必ず指定する\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/jsonlines\"],\n",
    "    response_types=[\"application/jsonlines\"],\n",
    "    inference_instances=[deploy_instance_type],\n",
    "    transform_instances=[\"ml.m5.4xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デプロイステップのためのモデルの作成\n",
    "\n",
    "![](img/pipeline-5.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = \"bert-model-{}\".format(timestamp)\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    image_uri=inference_image_uri,\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=sess,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "create_inputs = CreateModelInput(\n",
    "    instance_type=deploy_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "create_step = CreateModelStep(\n",
    "    name=\"CreateModel\",\n",
    "    model=model,\n",
    "    inputs=create_inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 条件付きデプロイステップ\n",
    "![](img/pipeline-6.png)\n",
    "\n",
    "最後に、評価ステップで測定したモデルのaccuracyが所定の閾値を超えた場合にのみ、このモデルを登録するようにしたいと思います。\n",
    "`ConditionStep`により、ステップのプロパティの条件に基づいて、パイプラインのDAG内での条件付き実行をサポートします。\n",
    "\n",
    "以降では、次の3つを実行します。\n",
    "\n",
    "* 評価ステップの出力に含まれるaccuracy値に対して、`ConditionGreaterThan`を定義\n",
    "* `ConditionStep` の条件リストで、この条件を使用\n",
    "* `RegisterModel` ステップコレクションを `ConditionStep` の `if_steps` に渡す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "\n",
    "min_accuracy_value = ParameterFloat(name=\"MinAccuracyValue\", default_value=0.10)\n",
    "\n",
    "minimum_accuracy_condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=evaluation_step,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\",\n",
    "    ),\n",
    "    right=min_accuracy_value,  # accuracy\n",
    ")\n",
    "\n",
    "minimum_accuracy_condition_step = ConditionStep(\n",
    "    name=\"AccuracyCondition\",\n",
    "    conditions=[minimum_accuracy_condition],\n",
    "    if_steps=[register_step, create_step],  # 条件を満たしたらモデル登録に進む\n",
    "    else_steps=[],  # 満たさなかったらパイプラインを終了する\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パラメータ、ステップ、条件のパイプラインを定義する\n",
    "\n",
    "これらをワークフローのパイプラインに結びつけて、実行したり、スケジューリングしたりできるようにしましょう。\n",
    "\n",
    "パイプラインには、`name`、`parameters`、`steps`が必要です。\n",
    "名前は `(account, region)` のペアの中でユニークでなければならないので、名前にタイムスタンプを加えます。\n",
    "\n",
    "以下に注意してください。\n",
    "\n",
    "* 定義時に使用されているすべてのパラメータが存在する必要がある。\n",
    "* パイプラインに渡されるステップは、実行順である必要はない。SageMaker Workflowサービスが、ステップ間の _データ依存性_ のDAGを解決する。\n",
    "* ステップは、パイプラインのステップリストまたは単一の条件ステップのif/elseリストのいずれかに一意でなければならない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMakerへパイプラインを送信して実行\n",
    "\n",
    "パイプラインの定義をワークフローサービスに送信してみましょう。\n",
    "渡されたロールは、ステップで定義されたすべてのジョブを作成するために、ワークフローサービスによって使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプラインを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _以下の `WARNING` は無視してください。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "existing_pipelines = 0\n",
    "\n",
    "existing_pipelines_response = sm.list_pipelines(\n",
    "    PipelineNamePrefix=pipeline_name,\n",
    "    SortOrder=\"Descending\",\n",
    ")\n",
    "\n",
    "if \"PipelineSummaries\" in existing_pipelines_response.keys():\n",
    "    if len(existing_pipelines_response[\"PipelineSummaries\"]) > 0:\n",
    "        existing_pipelines = existing_pipelines + 1\n",
    "        print(\"[INFO] You already have created {} pipeline with name {}.\".format(existing_pipelines, pipeline_name))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "if existing_pipelines == 0:  # パイプラインの作成は一度だけ\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            input_data,\n",
    "            processing_instance_count,\n",
    "            processing_instance_type,\n",
    "            max_seq_length,\n",
    "            balance_dataset,\n",
    "            train_split_percentage,\n",
    "            validation_split_percentage,\n",
    "            test_split_percentage,\n",
    "            feature_store_offline_prefix,\n",
    "            feature_group_name,\n",
    "            train_instance_type,\n",
    "            train_instance_count,\n",
    "            epochs,\n",
    "            learning_rate,\n",
    "            epsilon,\n",
    "            train_batch_size,\n",
    "            validation_batch_size,\n",
    "            test_batch_size,\n",
    "            train_steps_per_epoch,\n",
    "            validation_steps,\n",
    "            test_steps,\n",
    "            train_volume_size,\n",
    "            use_xla,\n",
    "            use_amp,\n",
    "            freeze_bert_layer,\n",
    "            enable_sagemaker_debugger,\n",
    "            enable_checkpointing,\n",
    "            enable_tensorboard,\n",
    "            input_mode,\n",
    "            run_validation,\n",
    "            run_test,\n",
    "            run_sample_predictions,\n",
    "            min_accuracy_value,\n",
    "            model_approval_status,\n",
    "            deploy_instance_type,\n",
    "            deploy_instance_count,\n",
    "        ],\n",
    "        steps=[processing_step, training_step, evaluation_step, minimum_accuracy_condition_step],\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "\n",
    "    pipeline.create(role_arn=role)[\"PipelineArn\"]\n",
    "    print(\"Created pipeline with name {}\".format(pipeline_name))\n",
    "else:\n",
    "    print(\n",
    "        \"****************************************************************************************************************\"\n",
    "    )\n",
    "    print(\n",
    "        \"You have already create a pipeline with the name {}. This is OK. Please continue to the next cell.\".format(\n",
    "            pipeline_name\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"****************************************************************************************************************\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _ここの `WARNING` は無視してください。_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプラインの実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _以下での `WARNING` は無視してください。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_executions = 0\n",
    "completed_executions = 0\n",
    "\n",
    "if existing_pipelines > 0:\n",
    "    existing_pipeline_executions_response = sm.list_pipeline_executions(\n",
    "        PipelineName=pipeline_name,\n",
    "        SortOrder=\"Descending\",\n",
    "    )\n",
    "\n",
    "    if \"PipelineExecutionSummaries\" in existing_pipeline_executions_response.keys():\n",
    "        if len(existing_pipeline_executions_response[\"PipelineExecutionSummaries\"]) > 0:\n",
    "            execution = existing_pipeline_executions_response[\"PipelineExecutionSummaries\"][0]\n",
    "            if \"PipelineExecutionStatus\" in execution:\n",
    "                if execution[\"PipelineExecutionStatus\"] == \"Executing\":\n",
    "                    running_executions = running_executions + 1\n",
    "                else:\n",
    "                    completed_executions = completed_executions + 1\n",
    "\n",
    "            print(\n",
    "                \"[INFO] You have {} Pipeline execution(s) currently running and {} execution(s) completed.\".format(\n",
    "                    running_executions, completed_executions\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if running_executions == 0:  # リソースの使用を制限するため同時のパイプライン実行はひとつに絞る\n",
    "    execution = pipeline.start(\n",
    "        parameters=dict(\n",
    "            InputData=raw_input_data_s3_uri,\n",
    "            ProcessingInstanceCount=1,\n",
    "            ProcessingInstanceType=\"ml.c5.2xlarge\",\n",
    "            MaxSeqLength=64,\n",
    "            BalanceDataset=\"True\",\n",
    "            TrainSplitPercentage=0.9,\n",
    "            ValidationSplitPercentage=0.05,\n",
    "            TestSplitPercentage=0.05,\n",
    "            FeatureStoreOfflinePrefix=feature_store_offline_prefix,\n",
    "            FeatureGroupName=feature_group_name,\n",
    "            LearningRate=0.000012,\n",
    "            TrainInstanceType=\"ml.c5.9xlarge\",\n",
    "            TrainInstanceCount=1,\n",
    "            Epochs=1,\n",
    "            Epsilon=0.00000001,\n",
    "            TrainBatchSize=128,\n",
    "            ValidationBatchSize=128,\n",
    "            TestBatchSize=128,\n",
    "            TrainStepsPerEpoch=50,\n",
    "            ValidationSteps=50,\n",
    "            TestSteps=50,\n",
    "            TrainVolumeSize=256,\n",
    "            UseXLA=\"True\",\n",
    "            UseAMP=\"True\",\n",
    "            FreezeBERTLayer=\"False\",\n",
    "            EnableSageMakerDebugger=\"False\",\n",
    "            EnableCheckpointing=\"False\",\n",
    "            EnableTensorboard=\"False\",\n",
    "            InputMode=\"File\",\n",
    "            RunValidation=\"True\",\n",
    "            RunTest=\"False\",\n",
    "            RunSamplePredictions=\"False\",\n",
    "            MinAccuracyValue=0.10,\n",
    "            ModelApprovalStatus=\"PendingManualApproval\",\n",
    "            DeployInstanceType=\"ml.m5.4xlarge\",\n",
    "            DeployInstanceCount=1,\n",
    "        )\n",
    "    )\n",
    "    running_executions = running_executions + 1\n",
    "    print(\"Started pipeline {}.  Ignore any warnings above.\".format(pipeline_name))\n",
    "    print(execution.arn)\n",
    "else:\n",
    "    print(\n",
    "        \"********************************************************************************************************************\"\n",
    "    )\n",
    "    print(\n",
    "        \"You have already launched {} pipeline execution(s).  This is OK.  Please continue to see the next cell.\".format(\n",
    "            running_executions\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"********************************************************************************************************************\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _^^ ここ ^^ での `WARNING` はすべて無視してください。_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプラインの完了まで待機してください。\n",
    "\n",
    "### _次のセルの実行には40分程度かかります。しばらくお待ちください。_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)[\"PipelineExecutionSummaries\"]\n",
    "pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "print(pipeline_execution_status)\n",
    "\n",
    "while pipeline_execution_status == \"Executing\":\n",
    "    try:\n",
    "        executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)[\"PipelineExecutionSummaries\"]\n",
    "        pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "    except Exception as e:\n",
    "        print(\"Please wait...\")\n",
    "        time.sleep(30)\n",
    "\n",
    "pprint(executions_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _^^ ここ ^^ のパイプライン実行が完了するまでお待ちください。_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完了したらパイプライン実行ステップとステータスを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "pipeline_execution_arn = executions_response[0][\"PipelineExecutionArn\"]\n",
    "\n",
    "print(\"Pipeline execution status {}\".format(pipeline_execution_status))\n",
    "print(\"Pipeline execution arn {}\".format(pipeline_execution_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "steps = sm.list_pipeline_execution_steps(PipelineExecutionArn=pipeline_execution_arn)\n",
    "\n",
    "pprint(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パイプラインで生成されたすべてのアーティファクトを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_name = None\n",
    "training_job_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.lineage.visualizer import LineageTableVisualizer\n",
    "\n",
    "viz = LineageTableVisualizer(sagemaker.session.Session())\n",
    "\n",
    "for execution_step in reversed(steps[\"PipelineExecutionSteps\"]):\n",
    "    print(execution_step)\n",
    "    # We are doing this because there appears to be a bug of this LineageTableVisualizer handling the Processing Step\n",
    "    if execution_step[\"StepName\"] == \"Processing\":\n",
    "        processing_job_name = execution_step[\"Metadata\"][\"ProcessingJob\"][\"Arn\"].split(\"/\")[-1]\n",
    "        print(processing_job_name)\n",
    "        display(viz.show(processing_job_name=processing_job_name))\n",
    "    elif execution_step[\"StepName\"] == \"Train\":\n",
    "        training_job_name = execution_step[\"Metadata\"][\"TrainingJob\"][\"Arn\"].split(\"/\")[-1]\n",
    "        print(training_job_name)\n",
    "        display(viz.show(training_job_name=training_job_name))\n",
    "    else:\n",
    "        display(viz.show(pipeline_execution_step=execution_step))\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パイプライン実行をExperimentのTrialとして追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -aws-processing-job is the default name assigned by ProcessingJob\n",
    "processing_job_tc = \"{}-aws-processing-job\".format(processing_job_name)\n",
    "print(processing_job_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.associate_trial_component(TrialComponentName=processing_job_tc, TrialName=pipeline_trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -aws-training-job is the default name assigned by TrainingJob\n",
    "training_job_tc = \"{}-aws-training-job\".format(training_job_name)\n",
    "print(training_job_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.associate_trial_component(TrialComponentName=training_job_tc, TrialName=pipeline_trial_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Debuggerの結果を分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_estimator = sagemaker.estimator.Estimator.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}?prefix={}/\">S3 Debugger Output Data</a></b>'.format(\n",
    "            bucket, restored_estimator.base_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Debuggerのプロファイリングレポートをダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_report_s3_uri = \"s3://{}/{}/rule-output/ProfilerReport/profiler-output\".format(\n",
    "    bucket, restored_estimator.base_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $profiler_report_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $profiler_report_s3_uri ./generated_profiler_report/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML('<b>Review <a target=\"blank\" href=\"./generated_profiler_report/profiler-report.html\">Profiler Report</a></b>')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _^^ Click `Trust HTML` in the profiler-report.html tab that opens ^^_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Studio内でプロファイリングレポートをレビュー\n",
    "\n",
    "![SageMaker Studio Extensions](img/studio_pipeline_training_debugger_assigned.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Studio内でパイプラインをレビュー\n",
    "![SageMaker Studio Extensions](img/sm_studio_extensions_pipelines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リソースを解放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
